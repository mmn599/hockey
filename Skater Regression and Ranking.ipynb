{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Finding Goals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [01:51<06:18, 34.43s/it]"
     ]
    }
   ],
   "source": [
    "import learning\n",
    "from IPython.core import display as ICD\n",
    "import pandas as pd\n",
    "from mord import OrdinalRidge\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "pd.options.display.max_columns = 999\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from tqdm import tqdm\n",
    "\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    MLPRegressor(), \n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20, 20), random_state=1),\n",
    "    KNeighborsClassifier(1),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=30, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    AdaBoostClassifier(n_estimators=100),\n",
    "    AdaBoostClassifier(n_estimators=200),\n",
    "    GaussianNB()]\n",
    "\n",
    "def trykfeatures(output, train, test, model):\n",
    "    _, Xtrain, ytrain = learning.prepare_base_data(train, output=output)\n",
    "    _, Xtest, ytest = learning.prepare_base_data(test, output=output)\n",
    "    minscore = 10000\n",
    "    for k in range(1, 17):\n",
    "        skb = SelectKBest(f_regression, k=k)\n",
    "        skb.fit(Xtrain, ytrain)\n",
    "        Xt = skb.transform(Xtrain)\n",
    "        model.fit(Xt, ytrain)\n",
    "        trues, preds, score = learning.score(test, {output: model}, {output: skb})\n",
    "        if(score<minscore):\n",
    "            finalskb = skb\n",
    "            finalmodel = model\n",
    "            minscore = score\n",
    "    return finalskb, finalmodel, minscore\n",
    "\n",
    "def trymodels(output, train, test, models):\n",
    "    print('Finding ' + output)\n",
    "    minscore = 10000\n",
    "    for model in tqdm(models):\n",
    "        finalskb, finalmodel, modelminscore = trykfeatures(output, train, test, model)\n",
    "        if(modelminscore<minscore):\n",
    "            chosenmodel = finalmodel\n",
    "            chosenskb = finalskb\n",
    "            minscore = modelminscore\n",
    "    return chosenmodel, chosenskb, minscore\n",
    "\n",
    "train = learning.get_base_data(2015)\n",
    "test = learning.get_base_data(2014)\n",
    "\n",
    "outputs = [\"Goals\", \"Assists\", \"Shots\", \"Blocks\"]\n",
    "fmodels = {}\n",
    "fskbs = {}\n",
    "fscores = {}\n",
    "\n",
    "print('Starting...')\n",
    "for output in outputs:\n",
    "    m, skb, score = trymodels(output, train, test, models)\n",
    "    print(output)\n",
    "    print(m)\n",
    "    print(skb)\n",
    "    print(score)\n",
    "    fmodels[output] = m\n",
    "    fskbs[output] = skb\n",
    "    fscores[output] = score\n",
    "    \n",
    "true, pred, score = learning.score(test, fmodels, featuresd=fskbs)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import learning\n",
    "for key, value in fskbs.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "true, pred, score = learning.score(test, fmodels, featuresd=fskbs)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
