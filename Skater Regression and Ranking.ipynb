{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import learning\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core import display as ICD\n",
    "import pandas as pd\n",
    "from mord import OrdinalRidge\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "pd.options.display.max_columns = 999\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from tqdm import tqdm\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVR\n",
    "import copy\n",
    "\n",
    "def trystuff(output, train, test, models, transforms):\n",
    "    minscore = 10000\n",
    "    modeldict = {}\n",
    "    _, Xtrain, ytrain = learning.prepare_base_data(train, output=output)\n",
    "    transforms = copy.deepcopy(transforms)\n",
    "    for transform in transforms:\n",
    "        transform.fit(Xtrain, ytrain)\n",
    "        Xt = transform.transform(Xtrain)\n",
    "        models = copy.deepcopy(models)\n",
    "        for model in models:\n",
    "            model.fit(Xt, ytrain)\n",
    "            if(output==\"FPoints\"):\n",
    "                trues, preds, score = learning.score_overall(test, model, transform)\n",
    "            else:\n",
    "                trues, preds, score = learning.score(test, {output: model}, {output: transform})\n",
    "            modeldict[(transform, model)] = score\n",
    "            if(score < minscore):\n",
    "                avgtrues = np.mean(trues)\n",
    "                avgpreds = np.mean(preds)\n",
    "                besttrans = transform\n",
    "                bestmodel = model\n",
    "                minscore = score\n",
    "    return modeldict, bestmodel, besttrans, minscore, avgtrues, avgpreds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Goals\n",
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "SelectKBest(k=5, score_func=<function f_regression at 0x000001F4582FE9D8>)\n",
      "25.8275862069\n",
      "36.0689655172\n",
      "10.2413793103\n",
      "Assists\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "SelectKBest(k=5, score_func=<function f_regression at 0x000001F4582FE9D8>)\n",
      "21.6781609195\n",
      "31.724137931\n",
      "10.0459770115\n",
      "Shots\n",
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "SelectKBest(k=6, score_func=<function f_regression at 0x000001F4582FE9D8>)\n",
      "11.132183908\n",
      "26.591954023\n",
      "15.4597701149\n",
      "Blocks\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "SelectKBest(k=5, score_func=<function f_regression at 0x000001F4582FE9D8>)\n",
      "8.31609195402\n",
      "18.6551724138\n",
      "10.3390804598\n",
      "34.7586206897\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    LinearRegression(),\n",
    "    MLPRegressor(),\n",
    "#     MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20, 20), random_state=1),\n",
    "    KNeighborsClassifier(5)\n",
    "]\n",
    "\n",
    "transforms = [\n",
    "    SelectKBest(f_regression, k=5),\n",
    "    SelectKBest(f_regression, k=6)\n",
    "#     SelectKBest(f_regression, k=7),\n",
    "#     SelectKBest(f_regression, k=8),\n",
    "#     SelectKBest(f_regression, k=9),\n",
    "#     SelectKBest(f_regression, k=10),\n",
    "#     SelectKBest(f_regression, k=11),\n",
    "#     SelectKBest(f_regression, k=12),\n",
    "#     SelectKBest(f_regression, k=13),\n",
    "#     SelectKBest(f_regression, k=14),\n",
    "#     SelectKBest(f_regression, k=15),\n",
    "#     SelectKBest(f_regression, k=16)\n",
    "]\n",
    "\n",
    "train = learning.get_base_data(2015)\n",
    "test = learning.get_base_data(2014)\n",
    "\n",
    "outputs = [\"Goals\", \"Assists\", \"Shots\", \"Blocks\"]\n",
    "fmodels = {}\n",
    "ftrans = {}\n",
    "fscores = {}\n",
    "\n",
    "print('Starting...')\n",
    "for output in outputs:\n",
    "    print(output)\n",
    "    modeldict, m, trans, score, avgtrues, avgpreds = trystuff(output, train, test, models, transforms)\n",
    "    print(m)\n",
    "    print(trans)\n",
    "    print(score)\n",
    "    print(avgtrues)\n",
    "    print(avgpreds)\n",
    "    joblib.dump(modeldict, output + \"_\" + \"modeldict.p\")\n",
    "    fmodels[output] = m\n",
    "    ftrans[output] = trans\n",
    "    fscores[output] = score\n",
    "    \n",
    "true, pred, score = learning.score(test, fmodels, ftrans)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "PCA(copy=True, iterated_power='auto', n_components=12, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n",
      "Average fantasy points with our model: 38.4195402299\n",
      "Optimal average fantasy points: 72.4137931034\n",
      "MSE: 33.9942528736\n"
     ]
    }
   ],
   "source": [
    "import learning\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    MLPRegressor(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    SVR()\n",
    "]\n",
    "\n",
    "transforms = [\n",
    "    PCA(n_components=1),\n",
    "    PCA(n_components=2),\n",
    "    PCA(n_components=3),\n",
    "    PCA(n_components=4),\n",
    "    PCA(n_components=5),\n",
    "    PCA(n_components=6),\n",
    "    PCA(n_components=7),\n",
    "    PCA(n_components=8),\n",
    "    PCA(n_components=9),\n",
    "    PCA(n_components=10),\n",
    "    PCA(n_components=11),\n",
    "    PCA(n_components=12),\n",
    "    PCA(n_components=13),\n",
    "    PCA(n_components=14),\n",
    "    PCA(n_components=15)\n",
    "]\n",
    "\n",
    "train = learning.get_base_data(2015)\n",
    "test = learning.get_base_data(2014)\n",
    "\n",
    "print('Starting...')\n",
    "modeldict, fmodel, ftrans, score, avgtrues, avgpreds = trystuff(\"FPoints\", train, test, models, transforms)\n",
    "joblib.dump(modeldict, \"FPoints\" + \"_\" + \"modeldict.p\")\n",
    "print(fmodel)\n",
    "print(ftrans)\n",
    "print(\"Average fantasy points with our model: \" + str(avgpreds))\n",
    "print(\"Optimal average fantasy points: \" + str(avgtrues))\n",
    "print(\"MSE: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
